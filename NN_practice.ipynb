{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural net workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NN functions\n",
    "'''\n",
    "# def nonlinear g(x) for transformation into 0 to 1 scale\n",
    "# is there a way to do this with ReLU? look at ISLR notes \n",
    "def sig(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "def dsig(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# def training function(s)\n",
    "def nxt_layer(inputs, synap_weights):\n",
    "    # obtain next layer from multiplying the inputs by the synaptic weights\n",
    "    return sig(np.dot(inputs, synap_weights)) # returns \n",
    "\n",
    "# n is the number of iterations\n",
    "def training(synap_weights, inputs, outputs, n):\n",
    "    \n",
    "    for n in range(n):\n",
    "        # find the output your network produces\n",
    "        nn_output = nxt_layer(inputs, synap_weights) # 1x5 matrix\n",
    "        \n",
    "        # cost = (pred - actual)**2, where pred is product of sigmoid(x)\n",
    "        # in this network, the a fn is just sigmoid(net_output)\n",
    "        cost = (outputs - nn_output)**2 # 1x5 matrix\n",
    "        \n",
    "        # compute gradient to find the change in the weights (result: 2Lx1 matrix where L is layer number)\n",
    "        dcost = (2*outputs - nn_output)\n",
    "        \n",
    "        # here, our simplified dC/dw and dC/db are the same function\n",
    "        grad_cost = np.dot(inputs.T, dcost * dsig(nn_output)) # 4x5 dot 1x5 = 4x1 matrix\n",
    "        synap_weights += grad_cost\n",
    "        \n",
    "    return synap_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CNN functions \n",
    "'''\n",
    "# convolution functions from the internet... tensorflow for computer vision, towardsdatascience\n",
    "# calculate dim of img after convolution (assumes img and filter are square)\n",
    "def calculate_target_size(img_size: int, kernel_size: int) -> int:\n",
    "    num_pixels = 0\n",
    "    \n",
    "    # From 0 up to img size (if img size = 224, then up to 223)\n",
    "    for i in range(img_size):\n",
    "        # Add the kernel size (let's say 3) to the current i\n",
    "        added = i + kernel_size\n",
    "        # It must be lower than the image size\n",
    "        if added <= img_size:\n",
    "            # Increment if so\n",
    "            num_pixels += 1\n",
    "            \n",
    "    return num_pixels\n",
    "\n",
    "\n",
    "# the actual convolution ... where kernel = filter\n",
    "def convolve(img: np.array, kernel: np.array) -> np.array:\n",
    "    # Assuming a rectangular image\n",
    "    tgt_size = calculate_target_size(\n",
    "        img_size=img.shape[0],\n",
    "        kernel_size=kernel.shape[0]\n",
    "    )\n",
    "    # To simplify things\n",
    "    k = kernel.shape[0]\n",
    "    \n",
    "    # 2D array of zeros\n",
    "    convolved_img = np.zeros(shape=(tgt_size, tgt_size))\n",
    "    \n",
    "    # Iterate over the rows\n",
    "    for i in range(tgt_size):\n",
    "        # Iterate over the columns\n",
    "        for j in range(tgt_size):\n",
    "            # img[i, j] = individual pixel value\n",
    "            # Get the current matrix\n",
    "            mat = img[i:i+k, j:j+k]\n",
    "            \n",
    "            # Apply the convolution - element-wise multiplication and summation of the result\n",
    "            # Store the result to i-th row and j-th column of our convolved_img array\n",
    "            convolved_img[i, j] = np.sum(np.multiply(mat, kernel))\n",
    "            \n",
    "    return convolved_img\n",
    "\n",
    "# stride size is the amount you move to get to the next pool\n",
    "def get_pools(img: np.array, pool_size: int, stride: int) -> np.array:\n",
    "    # To store individual pools\n",
    "    pools = []\n",
    "    \n",
    "    # Iterate over all row blocks (single block has `stride` rows)\n",
    "    for i in np.arange(img.shape[0], step=stride):\n",
    "        # Iterate over all column blocks (single block has `stride` columns)\n",
    "        for j in np.arange(img.shape[0], step=stride):\n",
    "            \n",
    "            # Extract the current pool\n",
    "            mat = img[i:i+pool_size, j:j+pool_size]\n",
    "            \n",
    "            # Make sure it's rectangular - has the shape identical to the pool size\n",
    "            if mat.shape == (pool_size, pool_size):\n",
    "                # Append to the list of pools\n",
    "                pools.append(mat)\n",
    "                \n",
    "    # Return all pools as a Numpy array\n",
    "    return np.array(pools)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### giving it a shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before CNN: \n",
      "filter1: \n",
      " [[0.14675589 0.09233859]\n",
      " [0.18626021 0.34556073]]\n",
      "filter2: \n",
      " [[0.39676747 0.53881673]\n",
      " [0.41919451 0.6852195 ]]\n",
      "Output:  [[0.65867017]]\n",
      "\n",
      "\n",
      "After CNN: \n",
      "filter1: \n",
      " [[0.52104937 0.56175707]\n",
      " [0.8871335  0.94355107]]\n",
      "filter2: \n",
      " [[1.33800068 1.52446515]\n",
      " [1.52324451 1.77478802]]\n",
      "Output:  [[0.99940587]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "baby heart: 3x3\n",
    "[[0, 0, 0],\n",
    " [1, 0, 1],\n",
    " [0, 1, 0]]\n",
    "2x2 filter -> 2x2 output\n",
    "2x2 filter -> binary output\n",
    "\n",
    "the heart: 5x5 matrix\n",
    "[[0, 1, 0, 1, 0],\n",
    " [1, 0, 1, 0, 1],\n",
    " [1, 0, 0, 0, 1], \n",
    " [0, 1, 0, 1, 0],\n",
    " [0, 0, 1, 0, 0]]\n",
    " try using a 3x3 filter -> 3x3 resulting image\n",
    " \n",
    "then use a 2x2 filter on the 3x3 -> 2x2 image\n",
    " \n",
    "another 2x2 filter on the 2x2 -> binary output\n",
    " '''\n",
    "\n",
    "baby_heart = np.array([[0, 0, 0],\n",
    "                       [1, 0, 1],\n",
    "                       [0, 1, 0]])\n",
    "filter1 = np.random.random((2, 2))\n",
    "filter2 = np.random.random((2, 2))\n",
    "correct_output = 1\n",
    "test_output = sig(convolve(convolve(baby_heart, filter1), filter2))\n",
    "print(\"Before CNN: \")\n",
    "print(\"filter1: \\n\", filter1)\n",
    "print(\"filter2: \\n\", filter2)\n",
    "print(\"Output: \", test_output)\n",
    "print(\"\\n\")\n",
    "\n",
    "for n in range(10):\n",
    "    # find the output your network produces\n",
    "    layer1 = convolve(baby_heart, filter1)\n",
    "    #print(layer1)\n",
    "\n",
    "    test_output = sig(convolve(layer1, filter2))\n",
    "    #print(test_output)\n",
    "\n",
    "    # dC for the connection between the layer and the output\n",
    "    dcost = (2*test_output - correct_output)\n",
    "    #print(dcost)\n",
    "\n",
    "    gradcost1 = dsig(dcost) * layer1 # sus\n",
    "    new_filter1 = filter1 + gradcost1\n",
    "    #print(new_filter1)\n",
    "\n",
    "    # dC for the connection between the input and the layer\n",
    "    dcost = (2*filter1 - new_filter1)\n",
    "    #print(dcost)\n",
    "\n",
    "    gradcost2 = dsig(dcost) * new_filter1 # my grad functions are sus\n",
    "    new_filter2 = filter2 + gradcost2\n",
    "    #print(new_filter2)\n",
    "\n",
    "    filter1 = new_filter1\n",
    "    filter2 = new_filter2\n",
    "    \n",
    "print(\"After CNN: \")\n",
    "test_output = sig(convolve(convolve(baby_heart, filter1), filter2))\n",
    "print(\"filter1: \\n\", filter1)\n",
    "print(\"filter2: \\n\", filter2)\n",
    "print(\"Output: \", test_output)\n",
    "    \n",
    "# manually collected stats: 75% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "Test weights: \n",
      " [[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]\n",
      " [-0.39533485]]\n",
      "Network output: \n",
      " [[0.2689864 ]\n",
      " [0.1734943 ]\n",
      " [0.23762817]\n",
      " [0.36375058]\n",
      " [0.1734943 ]] \n",
      "\n",
      "After training: \n",
      "New test weights in network: \n",
      " [[ 0.78385909]\n",
      " [-0.89871616]\n",
      " [-3.92642712]\n",
      " [10.2851889 ]]\n",
      "New network output: \n",
      " [[0.01933285]\n",
      " [0.99920995]\n",
      " [0.04138512]\n",
      " [0.00796151]\n",
      " [0.99920995]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "initiating a neural net\n",
    "note that all matrix notes are in row column order\n",
    "referenced amatullah's NN code\n",
    "'''\n",
    "\n",
    "# trying it out: single layer NN\n",
    "# initiate synaptic weights\n",
    "np.random.seed(1)\n",
    "test_weights = 2 * np.random.random((4, 1)) - 1 # initialize random synaptic weights in 4x1 matrix (rand * 2 - 1)\n",
    "\n",
    "test_inputs = np.array([[0, 0, 1, 0], [1, 0, 1, 1], [1, 0, 1, 0], [0, 1, 1, 0], [1, 0, 1, 1]])\n",
    "test_outputs = np.array([[0, 1, 0, 0, 1]]).T # 2D, 1x5 matrix\n",
    "print(\"Before training:\")\n",
    "print(\"Test weights: \\n\", test_weights)\n",
    "print(\"Network output: \\n\", nxt_layer(test_inputs, test_weights), \"\\n\")\n",
    "\n",
    "new_test_weights = training(test_weights, test_inputs, test_outputs, 1000)\n",
    "print(\"After training: \")\n",
    "print(\"New test weights in network: \\n\", new_test_weights)\n",
    "\n",
    "# see whether these new weights -> correct output\n",
    "print(\"New network output: \\n\", nxt_layer(test_inputs, new_test_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "Test weights: \n",
      " [[0.34832992]\n",
      " [0.80896286]\n",
      " [0.45963719]\n",
      " [0.6261243 ]]\n",
      "Network output: \n",
      " [[0.6129281 ]\n",
      " [0.807538  ]\n",
      " [0.69167614]\n",
      " [0.78050301]\n",
      " [0.807538  ]] \n",
      "\n",
      "After training: \n",
      "New test weights in network: \n",
      " [[ 7.10539303]\n",
      " [-1.06798136]\n",
      " [-0.95600473]\n",
      " [-1.12219649]]\n",
      "New network output: \n",
      " [[0.27767883]\n",
      " [0.99348552]\n",
      " [0.99786976]\n",
      " [0.11670745]\n",
      " [0.99348552]]\n"
     ]
    }
   ],
   "source": [
    "# another test run, but generating 1000 different samples rather than running training fn 1000 times\n",
    "\n",
    "test_weights = np.random.random((4, 1))\n",
    "test_inputs = np.array([[0, 0, 1, 0], [1, 0, 1, 1], [1, 0, 1, 0], [0, 1, 1, 0], [1, 0, 1, 1]])\n",
    "test_outputs = np.array([[0, 1, 0, 0, 1]]).T # 2D, 1x5 matrix\n",
    "print(\"Before training:\")\n",
    "print(\"Test weights: \\n\", test_weights)\n",
    "print(\"Network output: \\n\", nxt_layer(test_inputs, test_weights), \"\\n\")\n",
    "\n",
    "for i in range(100):\n",
    "    training_inputs = np.random.randint(0, 2, size = (5, 4)) # generate random test inputs between 0, 1\n",
    "    #print(training_inputs)\n",
    "    training_outputs = np.array([training_inputs[:, 0]]).T\n",
    "    #print(training_outputs)\n",
    "    \n",
    "    new_test_weights = training(test_weights, training_inputs, training_outputs, 1)\n",
    "    #print(new_test_weights)\n",
    "\n",
    "print(\"After training: \")\n",
    "print(\"New test weights in network: \\n\", new_test_weights)\n",
    "\n",
    "# see whether these new weights -> correct output\n",
    "# we expect each output to be around 0.5, since the assignment of the first column is random... confused\n",
    "print(\"New network output: \\n\", nxt_layer(test_inputs, new_test_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 8.]\n",
      " [4. 8.]]\n"
     ]
    }
   ],
   "source": [
    "# CNN processing != matrix multiplication\n",
    "# with matrix multiplication, rows of 1 need to equal the cols of 2 or vv\n",
    "# CNN process is doing dot product of subsections\n",
    "\n",
    "A = np.array([[0, 1, 2],\n",
    "              [0, 1, 2], \n",
    "              [0, 1, 2]])\n",
    "B = np.array([[0, 2],\n",
    "              [0, 2]])\n",
    "\n",
    "print(convolve(A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
